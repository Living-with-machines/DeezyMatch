{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: OCR example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from DeezyMatch import train as dm_train\n",
    "\n",
    "# train a new model\n",
    "dm_train(input_file_path=\"inputs/input_dfm.yaml\", \n",
    "         dataset_path=\"data/w2v_ocr_pairs_1860s.txt\", \n",
    "         model_name=\"ocr002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeezyMatch import plot_log\n",
    "\n",
    "# plot log file\n",
    "plot_log(path2log=\"./models/ocr002/log.txt\", \n",
    "         output_name=\"log_ocr002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from DeezyMatch import inference as dm_inference\n",
    "\n",
    "# # model inference using a model stored at pretrained_model_path and pretrained_vocab_path \n",
    "# dm_inference(input_file_path=\"inputs/input_dfm.yaml\",\n",
    "#              dataset_path=\"data/w2v_ocr_pairs_1860s.txt\", \n",
    "#              pretrained_model_path=\"./models/ocr002/ocr002.model\", \n",
    "#              pretrained_vocab_path=\"./models/ocr002/ocr002.vocab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate query vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeezyMatch import inference as dm_inference\n",
    "\n",
    "# generate vectors for queries (specified in dataset_path) \n",
    "# using a model stored at pretrained_model_path and pretrained_vocab_path \n",
    "dm_inference(input_file_path=\"inputs/input_dfm.yaml\",\n",
    "            dataset_path=\"data/queries_1870s.txt\", \n",
    "            pretrained_model_path=\"./models/ocr002/ocr002.model\", \n",
    "            pretrained_vocab_path=\"./models/ocr002/ocr002.vocab\",\n",
    "            inference_mode=\"vect\",\n",
    "            scenario=\"queries/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate candidate vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeezyMatch import inference as dm_inference\n",
    "\n",
    "# generate vectors for candidates (specified in dataset_path) \n",
    "# using a model stored at pretrained_model_path and pretrained_vocab_path \n",
    "dm_inference(input_file_path=\"inputs/input_dfm.yaml\",\n",
    "             dataset_path=\"data/candidates_1870s.txt\", \n",
    "             pretrained_model_path=\"./models/ocr002/ocr002.model\", \n",
    "             pretrained_vocab_path=\"./models/ocr002/ocr002.vocab\",\n",
    "             inference_mode=\"vect\",\n",
    "             scenario=\"candidates/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembling queries vector representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DeezyMatch import combine_vecs\n",
    "\n",
    "# combine vectors stored in queries/test and save them in combined/queries_test\n",
    "combine_vecs(rnn_passes=['fwd', 'bwd'], \n",
    "             input_scenario='queries/test', \n",
    "             output_scenario='combined/queries_test', \n",
    "             print_every=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembling candidates vector representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DeezyMatch import combine_vecs\n",
    "\n",
    "# combine vectors stored in candidates/test and save them in combined/candidates_test\n",
    "combine_vecs(rnn_passes=['fwd', 'bwd'], \n",
    "             input_scenario='candidates/test', \n",
    "             output_scenario='combined/candidates_test', \n",
    "             print_every=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DeezyMatch import candidate_ranker\n",
    "\n",
    "# Select candidates based on L2-norm distance (aka faiss distance):\n",
    "# find candidates from candidate_scenario \n",
    "# for queries specified in query_scenario\n",
    "candidates_pd = \\\n",
    "    candidate_ranker(query_scenario=\"./combined/queries_test\",\n",
    "                     candidate_scenario=\"./combined/candidates_test\", \n",
    "                     ranking_metric=\"faiss\", \n",
    "                     selection_threshold=50., \n",
    "                     num_candidates=2, \n",
    "                     search_size=2, \n",
    "                     verbose=False,\n",
    "                     use_predict=False,\n",
    "                     output_path=\"ranker_results/test_candidates_deezymatch\", \n",
    "                     pretrained_model_path=\"./models/ocr002/ocr002.model\", \n",
    "                     pretrained_vocab_path=\"./models/ocr002/ocr002.vocab\", \n",
    "                    #  number_test_rows=200)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "candidates_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_pd_tmp = candidates_pd[candidates_pd[\"faiss_distance\"].astype(str).str.contains(\"machine\", regex=False)]\n",
    "candidates_pd_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "61b4062b24dfb1010f420dad5aa3bd73a4d2af47d0ec44eafec465a35a9d7239"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
