{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: OCR example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the w2v model, from which the string pairs dataset\n",
    "# has been created:\n",
    "model_name = \"w2v_1760_1900\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from DeezyMatch import train as dm_train\n",
    "\n",
    "# train a new model\n",
    "dm_train(input_file_path=os.path.join(\"inputs\", \"input_dfm.yaml\"), \n",
    "         dataset_path=os.path.join(\"data\", f\"w2v_ocr_pairs_{model_name}.txt\"), \n",
    "         model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeezyMatch import plot_log\n",
    "\n",
    "# plot log file\n",
    "plot_log(path2log=os.path.join(\"models\", f\"{model_name}\", \"log.txt\"), \n",
    "         output_name=f\"log_{model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DeezyMatch import inference as dm_inference\n",
    "\n",
    "# model inference using a model stored at pretrained_model_path and pretrained_vocab_path \n",
    "dm_inference(input_file_path=os.path.join(\"inputs\", \"input_dfm.yaml\"),\n",
    "             dataset_path=os.path.join(\"data\", f\"w2v_ocr_pairs_{model_name}.txt\"), \n",
    "             pretrained_model_path=os.path.join(\"models\", f\"{model_name}\", f\"{model_name}.model\"), \n",
    "             pretrained_vocab_path=os.path.join(\"models\", f\"{model_name}\", f\"{model_name}.vocab\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate query vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeezyMatch import inference as dm_inference\n",
    "\n",
    "# generate vectors for queries (specified in dataset_path) \n",
    "# using a model stored at pretrained_model_path and pretrained_vocab_path \n",
    "dm_inference(input_file_path=os.path.join(\"inputs\", \"input_dfm.yaml\"),\n",
    "             dataset_path=os.path.join(\"data\", f\"queries_{model_name}.txt\"), \n",
    "             pretrained_model_path=os.path.join(\"models\", f\"{model_name}\", f\"{model_name}.model\"), \n",
    "             pretrained_vocab_path=os.path.join(\"models\", f\"{model_name}\", f\"{model_name}.vocab\"),\n",
    "             inference_mode=\"vect\",\n",
    "             scenario=\"queries/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate candidate vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeezyMatch import inference as dm_inference\n",
    "\n",
    "# generate vectors for candidates (specified in dataset_path) \n",
    "# using a model stored at pretrained_model_path and pretrained_vocab_path \n",
    "dm_inference(input_file_path=os.path.join(\"inputs\", \"input_dfm.yaml\"),\n",
    "             dataset_path=os.path.join(\"data\", f\"candidates_{model_name}.txt\"), \n",
    "             pretrained_model_path=os.path.join(\"models\", f\"{model_name}\", f\"{model_name}.model\"), \n",
    "             pretrained_vocab_path=os.path.join(\"models\", f\"{model_name}\", f\"{model_name}.vocab\"),\n",
    "             inference_mode=\"vect\",\n",
    "             scenario=\"candidates/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembling queries vector representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DeezyMatch import combine_vecs\n",
    "\n",
    "# combine vectors stored in queries/test and save them in combined/queries_test\n",
    "combine_vecs(rnn_passes=['fwd', 'bwd'], \n",
    "             input_scenario=os.path.join('queries', 'test'), \n",
    "             output_scenario=os.path.join('combined', 'queries_test'), \n",
    "             print_every=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembling candidates vector representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DeezyMatch import combine_vecs\n",
    "\n",
    "# combine vectors stored in candidates/test and save them in combined/candidates_test\n",
    "combine_vecs(rnn_passes=['fwd', 'bwd'], \n",
    "             input_scenario=os.path.join('candidates', 'test'), \n",
    "             output_scenario=os.path.join('combined', 'candidates_test'), \n",
    "             print_every=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DeezyMatch import candidate_ranker\n",
    "\n",
    "# Select candidates based on L2-norm distance (aka faiss distance):\n",
    "# find candidates from candidate_scenario \n",
    "# for queries specified in query_scenario\n",
    "candidates_pd = \\\n",
    "    candidate_ranker(query_scenario=os.path.join(\"combined\", \"queries_test\"),\n",
    "                     candidate_scenario=os.path.join(\"combined\", \"candidates_test\"), \n",
    "                     ranking_metric=\"faiss\", \n",
    "                     selection_threshold=50., \n",
    "                     num_candidates=2, \n",
    "                     search_size=2, \n",
    "                     verbose=False,\n",
    "                     use_predict=False,\n",
    "                     output_path=os.path.join(\"ranker_results\", \"test_candidates_deezymatch\"), \n",
    "                     pretrained_model_path=os.path.join(\"models\", f\"{model_name}\", f\"{model_name}.model\"), \n",
    "                     pretrained_vocab_path=os.path.join(\"models\", f\"{model_name}\", f\"{model_name}.vocab\"), \n",
    "                     number_test_rows=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "candidates_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeezyMatch import candidate_ranker\n",
    "\n",
    "# Select candidates based on L2-norm distance (aka faiss distance):\n",
    "# find candidates from candidate_scenario \n",
    "# for queries specified in query_scenario\n",
    "candidates_pd = \\\n",
    "    candidate_ranker(query=[\"vvater\"],\n",
    "                     candidate_scenario=os.path.join(\"combined\", \"candidates_test\"), \n",
    "                     ranking_metric=\"faiss\", \n",
    "                     selection_threshold=50., \n",
    "                     num_candidates=5, \n",
    "                     search_size=5, \n",
    "                     verbose=False,\n",
    "                     use_predict=False,\n",
    "                     output_path=os.path.join(\"ranker_results\", \"test_candidates_deezymatch\"), \n",
    "                     pretrained_model_path=os.path.join(\"models\", f\"{model_name}\", f\"{model_name}.model\"), \n",
    "                     pretrained_vocab_path=os.path.join(\"models\", f\"{model_name}\", f\"{model_name}.vocab\") \n",
    "                    #  number_test_rows=200)\n",
    "    )\n",
    "candidates_pd.iloc[0].faiss_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "61b4062b24dfb1010f420dad5aa3bd73a4d2af47d0ec44eafec465a35a9d7239"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
